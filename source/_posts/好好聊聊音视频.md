title: 好好聊聊音视频-第一弹
author: James
tags:

  - 视频
  - 音频
categories:
  - 直播
date: 2019-12-03 10:10:00

---

# 前言

五年来一直从事直播行业，经历过了*百播大战*， 一直也关注斗鱼、熊猫直播等平台从零开始内测到成长为巨头，目睹了一部分企业的最终倒闭。  5G时代即将来临，未来网络带宽和传输延迟都不再是瓶颈，视频、AR、AI和物联网一定会成为主流。 我也想聊聊关于音视频这方面的技术要点，同时好好沉淀下这几年在直播行业所学和所用的知识。
<!-- more -->

# 技术漫谈

 我们常说到直播技术，最先想到的就是音频技术和视频技术。 其实它们的大体处理流程都是差不多的。一般都分为五大步： 数据采集，编码，传输，解码和渲染。
![stream](/images/stream/streamcdn.png)

# 音视频技术

## 什么是视频
 不知道大家小时候是否玩过一种动画小人书，连续翻动的时候，小人书的画面就会变成一个动画。 
而视频的原理正是如此，由于人类眼睛的特殊结构，画面快速切换时，画面会有残留，感觉起来就是连贯的动作。所以，**视频就是由一系列图片构成的**。  

### 视频帧
帧，是视频的一个基本概念，表示一张画面，如翻页动画书中的一页，就是一帧。一个视频就是由许许多多帧组成的。 
### 帧率
帧率，即单位时间内帧的数量，单位为：帧/秒 或fps（frames per second）。如动画书中，一秒内包含多少张图片，图片越多，画面越顺滑，过渡越自然。 
### 色彩空间
这里我们只讲常用到的两种色彩空间。
- RGB
RGB的颜色模式应该是我们最熟悉的一种，在现在的电子设备中应用广泛。通过R G B三种基础色，可以混合出所有的颜色。
- YUV
这里着重讲一下YUV，这种色彩空间并不是我们熟悉的。这是一种亮度与色度分离的色彩格式。
早期的电视都是黑白的，即只有亮度值，即Y。有了彩色电视以后，加入了UV两种色度，形成现在的YUV，也叫YCbCr。
Y：亮度，就是灰度值。除了表示亮度信号外，还含有较多的绿色通道量。
U：蓝色通道与亮度的差值。
V：红色通道与亮度的差值。
**采用YUV有什么优势呢？**
> 人眼对亮度敏感，对色度不敏感，因此减少部分UV的数据量，人眼却无法感知出来，这样可以通过压缩UV的分辨率，在不影响观感的前提下，减小视频的体积。

## 音频是什么
音频数据的承载方式最常用的是**脉冲编码调制**，即**PCM**。 
在自然界中，声音是连续不断的，是一种模拟信号，那怎样才能把声音保存下来呢？那就是把声音数字化，即转换为数字信号。

### 采样率和采样位数
采样率：即采样的频率。
上面提到，采样率要大于原声波频率的2倍，人耳能听到的最高频率为20kHz，所以为了满足人耳的听觉要求，采样率至少为40kHz，通常为44.1kHz，更高的通常为48kHz。

采样位数：涉及到上面提到的振幅量化。波形振幅在模拟信号上也是连续的样本值，而在数字信号中，信号一般是不连续的，所以模拟信号量化以后，只能取一个近似的整数值，为了记录这些振幅值，采样器会采用一个固定的位数来记录这些振幅值，通常有8位、16位、32位。

### 声道数
声道数，是指支持能**不同发声**（注意是不同声音）的音响的个数。
单声道：1个声道；双声道：2个声道；立体声道：默认为2个声道；体声道（4声道）：4个声道

### 码率
码率，是指一个数据流中每秒钟能通过的信息量，单位bps（bit per second）
码率 = 采样率 * 采样位数 * 声道数

##  编码 
### 数据编码
数据采集完成之后，需要对数据进行压缩编码。音视频使用的压缩技术称为有损压缩技术。而像我们平RAR，ZIP工具进行的压缩都是无损压缩。就是说解压后的数据与原始数据一样叫做无损压缩，解压后和原始数据高度接近称为有损压缩，音视频编码属于后者。

### 音频编码
常用的编码格式有speex, AAC, OPUS, G.711等。现在比较常用的是AAC，一是它音质比较好，二是RTMP对AAC支持的比较好。对于视频编码格式有H.264, H.265, VP8, VP9等，目常基本上都是使用H.264。

衡量有损压缩好坏的指标就是看同等压缩率的情况下，解压后的数据与原始数据之间差别的大小，差别越小证明压缩的算法越优。当然在实时互动直播中，我们为了实时性就需要牺牲一部分质量或者也有可能为了质量而牺牲一些实时性，这需要仔细的权衡。

##  传输 
传输涉及到很多端：主播端→服务端→边缘节点→观看端
推流端和分发端 理论上需要支持的并发用户数应该都是亿级的，不过毕竟产生内容的推流端在少数，和消费内容端播放端不是一个量级，但是他们对推流稳定性和速度的要求比播放端高很多，这涉及到所有播放端能否看到直播和直播端质量如何。 
所以自己做传输基本不现实，推荐交给CDN服务商。CDN只提供了带宽和服务器 的传输，发送和接收端的网络连接抖动缓冲还是要自己写的。不想要卡顿， 必然要加大缓冲，加大缓冲会导致延迟高，延迟高影响互动性，要做权衡。

数据压缩完之后通过网络传输。对于泛娱乐化的直播平台一般都使用RTMP协议进行数据的传输，RTMP是在TCP之上的网络协议。对于实时互动直播则必须使用UDP进行数据传输。 UDP数据的传输速度上比TCP有天然的优势

### 协议相关
RTMP、FLV、HLS 、WebRTC技术 
**RTMP**:  是 Real Time Messaging Protocol（实时消息传输协议）的首字母缩写。该协议基于 TCP，是一个协议族，包括  RTMP 基本协议及 RTMPT/RTMPS/RTMPE 等多种变种。RTMP 是一种设计用来进行实时数据通信的网络协议，主要用来在  Flash/AIR 平台和支持 RTMP 协议的流媒体/交互服务器之间进行音视频和数据通信。支持该协议的软件包括 Adobe Media  Server/Ultrant Media Server/red5 等。
RTMP 是目前主流的流媒体传输协议，广泛用于直播领域，可以说市面上绝大多数的直播产品都采用了这个协议。
**WebRTC**: 名称源自网页即时通信（英语：Web Real-Time Communication）的缩写，是一个支持网页浏览器进行实时语音对话或视频对话的 API 

### 内容分发网络 CDN
构建一个全国性的全网覆盖网络，**将视频内容缓存或镜像到这些节点边缘服务器上**，为不同地域的不同用户提供视频内容加速服务。实现就近访问，从而加速访问速度，提升用户的访问体验，并可以**避免源站因访问量过大而造成的服务器负载过量与带宽资源不足等问题，解决网络拥塞，提高用户访问网站的响应速度**，有效保证用户体验。 
![flow](/images/stream/cdn.png)

# 总结
从视频、音频、编码和传输几个方面分别介绍了直播相关的知识，对于一个完整覆盖采集，推流，拉流和播放还有很多细节没有提到，可以先看看下面的架构图，未来还有第二第三弹继续介绍音视频直播的其他内容。

![flow](/images/stream/flow.png)

