title: 聊聊消息队列
author: James
tags:

  - 消息队列
categories:
  - 实战
date: 2019-04-22 10:51:00

---

# 简介

消息队列作为服务/应用之间的通信中间件，可以起到业务耦合、广播消息、保证最终一致性以及错峰流控（克服短板瓶颈）等作用。
自己公司线上运行着2个消息中间件：1.*RabbitMQ*，用于应用服务 2.*Kafka*，用与大数据数据上报和日志采集。既然使用了就不能只其然而不知其所以然， 故而好好研究消息队列，聊一聊自己的总结。

<!-- more -->

# 消息队列的使用场景

## 异步处理

**场景:**
​	我们是直播平台，用户送礼是最频繁的事情，用户在送完礼物后会触发一系列的后续动作。例如：排行榜计算、主播分成计算、徽章升级等等。
相应的传统做法：

1. 串行处理：所有的业务处理都在统一个服务内处理完。 
2. 并行处理：用户送礼完成后，同时并行计算排行榜、主播分成计算，用户徽章升级等等。
   假设三个业务节点每个使用10毫秒钟，不考虑网络等其他开销，则串行方式的时间是30毫秒，并行的时间可能是20毫秒。

**引入消息队列**：三个应用处理逻辑都异步处理，处理时间大约是在10毫秒内。

## 解耦

**场景：**
系统间耦合性太强，如系统A在代码中直接调用系统B和系统C的代码，如果将来D系统接入，系统A还需要修改代码，耦合性太强。将消息写入消息队列，需要消息的系统自己从消息队列中订阅，从而系统A不需要做任何修改。

## 流量削锋

**场景：**
直播冲榜活动：经常发生秒榜的行为，用户经常在活动截止的最后时刻同时送礼冲榜，导致流量爆炸，应用服务可能随时挂掉； 为了解决这个问题，引入了消息队列。用户的请求服务器接收后，首先写入消息队列，如果消息队列请求数达到和阈值，则直接抛弃用户的请求。

## 消息通讯

**场景：**
用户送礼：在用户送完礼好，需要通知直播间播放礼物，或者显示用户姓名。客户端socket订阅送礼的主题， 用户送完礼物后接口服务push消息到这个主题内。 消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等。

## 日志处理

**场景：**
我们的大数据用户行为数据上报：
- 日志采集客户端，负责日志数据采集，定时写受写入Kafka队列
- Kafka消息队列，负责日志数据的接收，存储和转发
- 日志处理应用：订阅并消费kafka队列中的日志数据

## 分布式事务

**场景**：
由于应用服务部署在不同的机器上，数据库也进行了拆分，所以会面临着分布式事务问题。如：用户送礼后调用主播成就计算服务。
可以通过消息补偿的分布式事务方案往往用在高并发场景下，将一个分布式事务拆成一个消息事务（A系统的本地操作+发消息）+B系统的本地操作，其中B系统的操作由消息驱动，只要消息事务成功，那么A操作一定成功，消息也一定发出来了，这时候B会收到消息去执行本地操作，如果本地操作失败，消息会重投，直到B操作成功，这样就变相地实现了A与B的分布式事务。

# 消息队列相关技术点梳理

## 基本架构
一般为：*producer，broker，consumer*

## 高可用
**集群高可用**：producer通过broker投递消息，所以必然有且仅有一个broker主负责“写”，选主策略分为自动选主和非主动选择，自动选主使用分布一致性组件完成，例如Kafka使用zookeeper，非自动选主。

**数据高可用**：针对broker持久化积压消息场景。可借助分布式存储完成，但是往往性能上是个短板，所以大多数主流产品都进行本地IO顺序写，进行主从备份，多副本拷贝保证可用性。

## 协议
producer、consumer和broker通信的协议，包括AMQP、STOMP、MQTT、HTTP、OpenWire（ActiveMQ）、XMPP、自定义等等。

AMQP是比较全面和复杂的一个协议，包括协议本身以及模型（broker、exchange、routing  key等概念），目前RabbitMQ是AMQP消息队列最有名的开源实现，有非常多语言已经支持基于AMQP协议与消息队列通信，同时还可以通过插件支持STOMP、MQTT等协议接入。Kafka、RocketMQ均使用自定义的协议。

## 消费关系

1. 点对点，也就是P2P，FIFO的队列，可以看做单播。
2. Topic模式，Pub/Sub发布订阅。
3. fanout广播模式。

## 消息堆积能力

持久化消息，如果存储在本地磁盘，可以使用同步刷盘和异步刷盘两种策略。磁盘不能无限堆积，会有清理策略，例如Kafka、RocketMQ都按照时间、数据量进行retention。

非持久化，仅放在内存，消费者处理完可选择删除掉。

## 可靠投递

对于producer，从API和I/O层面可使用同步、异步，对于吞吐层面可使用单条、批量。fire-and-forget模式，类似UDP，尽管发送即可。针对可能发生的错误，例如连接broker失败，RPC超时、发布消息失败、发布后无响应，可选择忽略或者重发，所以往往重复投递的情况不可避免。

对于broker，如果要保证数据100%不丢，是可能的，但是需要牺牲下性能和吞吐，使用同步多写、多副本策略+同步刷盘持久化消息，可以严格保证不丢。另外，broker对于写入消息的payload，也会做完整性校验，例如CRC等。

## 消费可靠性

**消费次数**: 包括at most once、at least once、exactly  once，其中前两个比较好做到，最后的exactly once需要streaming  consumer系统和broker端协作完成，例如storm的trident和flink。
**推拉模式**: push or pull。推模式最小化投递延迟，但是没有考虑consumer的承载能力，拉一般是轮询接收broker的数据，按照consumer自己的能力消费。
**消费记录点**: 一般每个消息都有一个offset、ID或者时间戳，consumer可以按照这个offset来进行定点消费以及消息重放。
**消息确认**: consumer消费完成ACK回调broker或者集群高可用中间件（zk）通知消费进度。
**错误处理**:对于消费失败的情况，可以回复NACK，要求重发/requeue消息，当错误超多一定阈值时候，放到死信队列中。
**消息重复消费**: 这和消费次数有关系，consumer在某些时候需要做到幂等性，保证重复消费不会引起业务异常。

# 常见问题

## 消息的幂等性

产生原因:网络延迟传输中，或者消费出现异常或者是消费延迟，会造成进行MQ重试进行重试补偿机制，在重试过程中，可能会造成重复消费。
*解决办法:*
其实无论是哪一种消息队列，造成重复消费原因其实都是类似的。正常情况下，消费者在消费消息时候，消费完毕后，会发送一个确认信息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除。只是不同的消息队列发送的确认信息形式不同,例如RabbitMQ是发送一个ACK确认消息，RocketMQ是返回一个CONSUME_SUCCESS成功标志，kafka实际上有个offset的概念,每一个消息都有一个offset，kafka消费过消息后，需要提交offset，让消息队列知道自己已经消费过了。

## 消息的重发补偿

  为了保证数据不被丢失，RabbitMQ支持消息确认机制，即acknowledgments。为了保证数据能被正确处理而不仅仅是被Consumer收到，那么我们不能采用no-ack。而应该是在处理完数据后发送ack。 在处理数据后发送的ack，就是告诉RabbitMQ数据已经被接收，处理完成，RabbitMQ可以去安全的删除它了。

## 消息的有序性

rabbitmq本身是没有绝对的消息顺序机制的，单个queue在多消费者下不能保证其先后顺序。  另外ack的机制会触发消息重复消费的，需要我们在设计上避免该问题。如果对于消息顺序敏感，那么我们这里给出的方法是 消息体通过hash分派到队列里，每个队列对应一个消费者，多分拆队列。  同一组的任务会被分配到同一个队列里，每个队列只能有一个worker来消费，这样避免了同一个队列多个消费者消费时，乱序的可能！ t1, t2 两个任务， t1 虽然被c1先pop了，但是有可能c2先把 t2 任务给完成了。 主动去分配队列，单个消费者。 

## 消息的堆积

在实际应用场景中什么情况下消息发送的速率远远大于消息消费的速率，比如某个时间段消费端处理消息异常缓慢（发送消息只要3秒钟，而消费消息需要1分钟左右才能处理一个消息，每分钟发送20个消息，只能有一个消息被消费端处理，这样队列中就会产生大量的消息堆积）。
当消费端处理缓慢造成的消息堆积就可以通过设置并发消费提高消费的速率，从而减少消息堆积的问题。
设置并发消费两个关键属性concurrentConsumers和prefetchCount。